from ultralytics import YOLO
import cv2
import face_recognition

# Load the YOLOv8 model
model = YOLO('yolov8n.pt')  # or 'yolov8s.pt' for better accuracy

# Load known faces and their names
known_face_encodings = [
    # Add face encodings for known individuals
    # For example: face_recognition.face_encodings(face_image)[0]
    people_image = face_recognition.load_image_file('people.jpg')
    people_face_encoding = face_recognition.face_encodings(people_image)[0]
    known_face_encodings.append(people_face_encoding)
    known_face_names.append('name of Person 1')
]
known_face_names = [
    'name of Person 1',
    'name of Person 2',
    # Add names corresponding to face encodings
]

# Start capturing video from the webcam
video_capture = cv2.VideoCapture(0)

while True:
    # Capture a single frame from the camera
    ret, frame = video_capture.read()
    if not ret:
        break
    
    # Run YOLOv8 to detect objects in the frame
    results = model(frame)

    # Process each detection result
    for result in results:
        detections = result.boxes.data  # All detected boxes with class labels and scores

        for detection in detections:
            # Unpack detection and only focus on 'person' class (class ID 0)
            x1, y1, x2, y2, confidence, class_id = detection[:6].tolist()
            if int(class_id) == 0:
                # Draw bounding box for person detection
                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)

                # Crop detected person region for facial recognition
                person_crop = frame[int(y1):int(y2), int(x1):int(x2)]
                
                # Face recognition to identify person
                face_encodings = face_recognition.face_encodings(person_crop)
                if face_encodings:
                    face_encoding = face_encodings[0]

                    # Check for matches with known faces
                    matches = face_recognition.compare_faces(known_face_encodings, face_encoding)
                    name = "Unknown"

                    # Use the known face with the smallest distance if match is found
                    face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)
                    best_match_index = min(range(len(face_distances)), key=face_distances.__getitem__)
                    if matches[best_match_index]:
                        name = known_face_names[best_match_index]

                    # Display the name
                    cv2.putText(frame, name, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
    
    # Display the video feed with detections
    cv2.imshow('Video', frame)

    # Break loop if 'q' is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the capture and close any OpenCV windows
video_capture.release()
cv2.destroyAllWindows()
